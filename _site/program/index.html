<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Stéphane Mallat's 60 birthday conference">

    <!-- Loading mathjax -->
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>


    <title>Program - Stéphane Mallat's 60 birthday conference</title>

    <link rel="canonical" href="http://localhost:4000/program/">

    <!-- Favicon -->
    <link rel="icon" type="image/png" href="/img/favicon.png">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/clean-blog.css">

    <script type="text/javascript" src="http://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>

    <!-- Custom Fonts -->
    <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- XML FEED -->

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>


<body>

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Home</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">

                <li>
                    <a href="/program">Program</a>
                </li>

            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>


    <!-- Page Header -->
<header class="intro-header" style="background-image: url('/img/hokusai-3.jpg')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="site-heading">
                    <h1>Program</h1>
                    <hr class="small">
                    <span class="subheading"></span>
                </div>
            </div>
        </div>
    </div>
</header>



<!-- Main Content -->
<div class="container">
	<div class="row">
		<div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
			<p><img src="img/schedule.png" alt="Schedule of the conference" /></p>

<h2 id="abstracts">Abstracts:</h2>

<p><strong>Richard Baranuik</strong><br />
<em>Title:</em> TBA.<br />
<em>Abstract:</em> TBA.</p>

<p><strong>Freddy Bruckstein</strong><br />
<em>Title:</em> TBA.<br />
<em>Abstract:</em> TBA.</p>

<p><strong>Akram Aldroubi</strong>, Vanderbilt University<br />
<em>Title:</em> Dynamical Sampling And Frames<br />
<em>Abstract:</em> Dynamical sampling is a term describing an emerging set of problems related to recovering signals and evolution operators from space-time samples. For example, consider the abstract IVP in a separable Hilbert space H: du/dt=Au+F. When, F=0, A is a known (or unknown) operator, and the goal is to recover u0 from the samples {u(ti,xj)} on a sampling set {(ti,xj)}, we get the so called space-time sampling problems. If the goal is to identify the operator A, or some of its characteristics, we get the system identification problems. If instead we wish to recover F, we get the source term problems. In this talk, I will present an overview of dynamical sampling, and some open problems.</p>

<p><strong>Emmanuel Candès</strong>, Stanford University<br />
<em>Title:</em> A Taste of conformal prediction<br />
<em>Abstract:</em> Conformal inference methods are becoming all the rage in academia and industry alike. In a nutshell, these methods deliver exact prediction intervals for future observations without making any distributional assumption whatsoever other than having iid, and more generally, exchangeable data. This talk will review the basic principles underlying conformal inference and survey some major contributions that have occurred in the last 2-3 years or. We will discuss enhanced conformity scores applicable to quantitative as well as categorical labels. If time allows, we will also survey novel methods which deal with situations, where the distribution of observations can shift drastically.</p>

<p><strong>Maureen Clerc</strong>, INRIA<br />
<em>Title:</em> Human attention and communication mediated via machine learning<br />
<em>Abstract:</em> The beauty of wavelets is that they are intuitively graspable, while being grounded in deep mathematical foundations. As Gabor wavelets are representative of visual perceptive fields, wavelets have been used to model biological principles of vision. Wavelets have in turn proved useful to extract information from brain activity,  by focusing on repeating patterns that emerge from noise. While machines are particularly apt at recognizing repetitive patterns, humans are expert at detecting departures from regularity. Neural markers related to departures from regularity are correlates of human attention, independently of sensory modality. Machines can be trained to measure this trace of attention in neural signals, which can provide novel ways to mediate communication between humans.</p>

<p><strong>Maarten De Hoop</strong><br />
<em>Title:</em> TBA.<br />
<em>Abstract:</em> TBA.</p>

<p><strong>David Donoho</strong>, Stanford University<br />
<em>Title:</em> The bridge from mathematical to digital, and back<br />
<em>Abstract:</em> Stephane Mallat has, across 30 years, evolved continuously as the fields of computational harmonic analysis, signal processing and image processing
have evolved. Starting out writing papers in Math journals like Trans Amer Math Soc, he recently has written papers for the leading conferences in empirical machine learning.  The transition that Stéphane has made is something we should all learn from, but I’m afraid many of us will not be able to understand or emulate. Indeed today there are vast differences in mindset and worldview between the mathematical and the digital communities.  They literally do not understand each other. I will describe the differences in mindsets and worldviews and provide a few travel tips for those people who would like to go on the bridge from mathematical to digital, or vice versa. (related to a manuscript under preparation with  Matan Gavish, Hebrew University)</p>

<p><strong>Miki Elad</strong>, Technion<br />
<em>Title:</em> The New Era of Image Denoising<br />
<em>Abstract:</em> Image denoising is one of the oldest and most studied problems in image processing. An extensive work over several decades has led to thousands of papers on this subject, and to many well-performing algorithms for this task. As expected, the era of deep learning has brought yet another revolution to this subfield, and took the lead in today’s ability for noise suppression in images. This talk focuses on recently discovered abilities and opportunities of image denoisers. We expose the possibility of using image denoisers for serving other problems, such as regularizing general inverse problems and serving as the engine for image synthesis. We also unveil the (strange?) idea that denoising and other inverse problems might not have a unique solution, as common algorithms would have you believe. Instead, we describe constructive ways to produce randomized and diverse high perceptual quality results for inverse problems.</p>

<p><strong>Remi Gribonval</strong><br />
<em>Title:</em> TBA.<br />
<em>Abstract:</em> TBA.</p>

<p><strong>Stéphane Jaffard</strong>, Université Paris-Est<br />
<em>Title:</em> Random Fourier series   vs.  random  wavelet series<br />
<em>Abstract:</em> The huge success of wavelet bases was the consequence of two key properties:  On one hand, the general framework of multiresolution analysis, built  by Stéphane Mallat, which led to the fast decomposition/reconstruction algorithms and to the  construction of compactly supported wavelets by Ingrid Daubechies;  and, on other hand,  the characterization of large classes of function spaces by simple conditions on wavelet coefficients, worked out by Yves Meyer (often referred to as the ``multiplier property’’) and  which had direct and practical consequences in  statistics and in signal and image processing. These characterizations imply that the norm of a function is not greatly modified if its  wavelet coefficients suffer  perturbations,  which guarantees the numerical robustness of the reconstruction of a function from it wavelet coefficients,  in sharp contradistinction with Fourier series. We will expose  surprizing consequences of this property, which implies  that  the regularity properties of random wavelet series strongly differ from   those of random Fourier series.</p>

<p><strong>Jerome Kalifa</strong><br />
<em>Title:</em> TBA.<br />
<em>Abstract:</em> TBA.</p>

<p><strong>Hamid Krim</strong>, NCSU, Raleigh NC<br />
<em>Title:</em> Learning with Volterra Series (VNNs)<br />
<em>Abstract:</em> Machine Learning (ML) has reached an unprecedented performance in various inference problems arising in practice. The sample complexity and that of the model have, however, increasingly emerged as a serious limitation. Given the importance of a number of problems where these issues are central, we have revisited the Conv-net fundamental principle and have reformulated it from a Volterra Series perspective using a polynomial functional paradigm*. We propose a computational Convolutional Network solution which requires no activation function and provides a very competitive inference performance (often better) at a fraction of the sample and model complexity of the most competitive CNN architecture. * Homogeneous Polynomial Functional were first developed and formalized by Frechet.</p>

<p><strong>Gitta Kutyniok</strong>,  LMU Munich<br />
<em>Title:</em> Reliable AI: From Applied Harmonic Analysis to Quantum Computing<br />
<em>Abstract:</em> The new wave of artificial intelligence is impacting industry, public life, and the sciences in an unprecedented manner. In mathematics, it has by now already led to paradigm changes in several areas. However, one current major drawback is the lack of reliability of such methodologies. In this talk, we will focus on the key aspects of reliability of deep neural networks, namely generalization and explainbility, and discuss a complete generalization result in the setting of graph neural networks and a novel explainbility approach based on applied harmonic analysis. Finally, we will briefly touch upon limitations as well, show that from a computability viewpoint digital hardware causes a serious problem for reliability, and reveal a surprising connection to novel computing approaches such as quantum computing.</p>

<p><strong>Yann Le Cun</strong><br />
<em>Title:</em> TBA.<br />
<em>Abstract:</em> TBA.</p>

<p><strong>Eric Moulines</strong><br />
<em>Title:</em> TBA.<br />
<em>Abstract:</em> TBA.</p>

<p><strong>Edouard Oyallon</strong><br />
<em>Title:</em> TBA.<br />
<em>Abstract:</em> TBA.</p>

<p><strong>Naoki Saito</strong>, UC Davis<br />
<em>Title:</em> Multiscale basis dictionaries and scattering networks on simplicial complexes<br />
<em>Abstract:</em> I will discuss multiscale basis dictionaries, in particular, the Hierarchical Graph Laplacian Eigen Transform (HGLET) and the Generalized Haar-Walsh Transform (GHWT), which my group originally developed for analyzing signals measured on nodes of an input graph, but which we have recently generalized for signals defined on edges, triangles, tetrahedra, etc. of a given simplicial complex using the Hodge Laplacians. These dictionaries consist of redundant sets of multiscale basis vectors and the corresponding expansion coefficients of a given signal. These provide a large number of orthonormal bases among which one can select the most suitable basis for one’s task using the best-basis algorithm and its relatives.
I will also discuss how to construct scattering networks for signals on simplicial complexes using the HGLET and the GHWT. Our new scattering networks cascade the moments (up to fourth order) of the modulus of the dictionary coefficients followed by the local averaging process. Consequently, the resulting features are robust to perturbations of input signals and invariant w.r.t. node permutations. I will demonstrate the usefulness of these dictionaries using the coauthorship/citation complex and the Science News article classification. This is joint work with Stefan Schonsheck and Eugene Shvarts.</p>

<p><strong>Guillermo Sapiro</strong>, Duke<br />
<em>Title:</em> A Large-Scale Observational Study of the Causa Effects of a Behavioral Health Nudge<br />
<em>Abstract:</em> Nudges are interventions promoting healthy behavior without forbidding
options or significant incentives; the Apple Watch, for example,
encourages users to stand by delivering a notification if they have
been sitting for the first 50 minutes of an hour. Based on 76 billion
minutes of observational standing data from 160,000 subjects
in the public Apple Heart and Movement Study, we estimate the
causal effect of this notification using a novel regression discontinuity
design for time-series data with time-varying treatment. We show
that the nudge increases the probability of standing by up to 43.9%,
and remains effective with time. The nudge’s effectiveness increases
with age and it is independent of gender. Closing Apple Watch Activity
Rings, a visualization of participants’ daily progress in Move,
Exercise, and Stand, further increases the nudge’s impact. This work
demonstrates the effectiveness of behavioral health interventions and
introduces tools for investigating their causal effect from observations.
Joint work with Achille Nazaret.</p>

<p><strong>Shihab Shamma</strong><br />
<em>Title:</em> TBA.<br />
<em>Abstract:</em> TBA.</p>

<p><strong>Eero Simoncelli</strong><br />
<em>Title:</em> TBA.<br />
<em>Abstract:</em> TBA.</p>

<p><strong>Jean-Jacques Slotine</strong>, MIT<br />
<em>Title:</em> Stable adaptation and learning<br />
<em>Abstract:</em> The human brain still largely outperforms robotic algorithms in most tasks, using computational elements 7 orders of magnitude slower than their artificial counterparts. Similarly, current large scale machine learning algorithms require millions of examples and close proximity to power plants, compared to the brain’s few examples and 20W consumption. We study how modern nonlinear systems tools, such as contraction analysis, virtual dynamical systems, and adaptive nonlinear control can yield quantifiable insights about collective computation and learning in large dynamical networks. For instance, we show how stable implicit sparse regularization can be exploited in adaptive prediction or control  to select relevant dynamic models out of plausible physically-based candidates, and how most elementary results on gradient descent based on convexity  can be replaced by much more general results based on Riemannian contraction.</p>

<p><strong>Michael Unser</strong><br />
<em>Title:</em> TBA.<br />
<em>Abstract:</em> TBA.</p>

<p><strong>Martin Vetterli</strong>, EPFL<br />
<em>Title:</em> Lippmann Photography: The Art and Science of Multispectral Imagery<br />
<em>Abstract:</em> Gabriel Lippmann won the 1908 Nobel Prize in Physics for colour photography. 
It is actually the first example of multispectral imaging. We provide a complete analysis of the process and show, both theoretically and experimentally, what spectrum is reflected from a Lippmann plate.  An algorithmic recovery of the original spectrum is proposed, as well as a digital version of Lippmann photography. We discuss the application to high density permanent three-dimensional storage, and finish with an example of science communication for the general public. Joint work with Gilles Baechler, Arnaud Latty, Michalina Pacholska,  Paolo Prandoni and Adam Scholefield. References: 1. Gilles Baechler, Arnaud Latty, Michalina Pacholska, Martin Vetterli, and Adam Scholefield,  “Shedding light on 19th century spectra by analyzing Lippmann photography,”  PNAS, April 27, 2021, Vol. 118, No. 17. ; 2.  Gilles Baechler, Arnaud Latty, Michalina Pacholska, Martin Vetterli, and Adam Scholefield,  “Lippmann Photography: A Signal Processing Perspective,”  IEEE Tr. on SP, July 2022.</p>

<p><strong>Irene Waldspurger</strong><br />
<em>Title:</em> TBA.<br />
<em>Abstract:</em> TBA.</p>

<p><strong>Bin Yu</strong><br />
<em>Title:</em> TBA.<br />
<em>Abstract:</em> TBA.</p>

		</div>
	</div>
</div>

<hr>

    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">

                    <li>
                        <a href="/feed.xml">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="https://twitter.com/gabrielpeyre">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                    <li>
                        <a href="https://github.com/gpeyre">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                </ul>
                <!--
                  <p class="copyright text-muted">Copyright &copy; Stéphane Mallat's 60 birthday conference 2023</p>
                -->
            </div>
        </div>
    </div>
</footer>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/clean-blog.min.js "></script>




<!-- Google analytics -->
<script src="http://www.google-analytics.com/urchin.js" type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-781488-2";
urchinTracker();
</script>


</body>

</html>
