---
layout: page
title: "Program"
description: ""
header-img: "img/hokusai-3.jpg"
---

![Schedule of the conference](img/schedule.png)


Abstracts: 
----

**Richard Baranuik**<br/>
_Title:_ TBA.<br/>
_Abstract:_ TBA.<br/>
_Keyrwords:_

**Freddy Bruckstein**<br/>
_Title:_ TBA.<br/>
_Abstract:_ TBA.<br/>
_Keyrwords:_

**Akram Aldroubi**, Vanderbilt University<br/>
_Title:_ Dynamical Sampling And Frames<br/>
_Abstract:_ Dynamical sampling is a term describing an emerging set of problems related to recovering signals and evolution operators from space-time samples. For example, consider the abstract IVP in a separable Hilbert space H: du/dt=Au+F. When, F=0, A is a known (or unknown) operator, and the goal is to recover u0 from the samples {u(ti,xj)} on a sampling set {(ti,xj)}, we get the so called space-time sampling problems. If the goal is to identify the operator A, or some of its characteristics, we get the system identification problems. If instead we wish to recover F, we get the source term problems. In this talk, I will present an overview of dynamical sampling, and some open problems.<br/>
_Keyrwords:_ sampling, frames, signal processing, system identification.

**Emmanuel Candès**, Stanford University<br/>
_Title:_ A Taste of conformal prediction<br/>
_Abstract:_ Conformal inference methods are becoming all the rage in academia and industry alike. In a nutshell, these methods deliver exact prediction intervals for future observations without making any distributional assumption whatsoever other than having iid, and more generally, exchangeable data. This talk will review the basic principles underlying conformal inference and survey some major contributions that have occurred in the last 2-3 years or. We will discuss enhanced conformity scores applicable to quantitative as well as categorical labels. If time allows, we will also survey novel methods which deal with situations, where the distribution of observations can shift drastically.<br/>
_Keyrwords:_ conformal inference, statistics, machine learning.

**Maureen Clerc**, INRIA<br/>
_Title:_ Human attention and communication mediated via machine learning<br/>
_Abstract:_ The beauty of wavelets is that they are intuitively graspable, while being grounded in deep mathematical foundations. As Gabor wavelets are representative of visual perceptive fields, wavelets have been used to model biological principles of vision. Wavelets have in turn proved useful to extract information from brain activity,  by focusing on repeating patterns that emerge from noise. While machines are particularly apt at recognizing repetitive patterns, humans are expert at detecting departures from regularity. Neural markers related to departures from regularity are correlates of human attention, independently of sensory modality. Machines can be trained to measure this trace of attention in neural signals, which can provide novel ways to mediate communication between humans.<br/>
_Keyrwords:_ visual perception, maching learning, wavelets, neuroscience.

**Maarten De Hoop**<br/>
_Title:_ TBA.<br/>
_Abstract:_ TBA.<br/>
_Keyrwords:_


**David Donoho**, Stanford University<br/>
_Title:_ The bridge from mathematical to digital, and back<br/>
_Abstract:_ Stephane Mallat has, across 30 years, evolved continuously as the fields of computational harmonic analysis, signal processing and image processing
have evolved. Starting out writing papers in Math journals like Trans Amer Math Soc, he recently has written papers for the leading conferences in empirical machine learning.  The transition that Stéphane has made is something we should all learn from, but I’m afraid many of us will not be able to understand or emulate. Indeed today there are vast differences in mindset and worldview between the mathematical and the digital communities.  They literally do not understand each other. I will describe the differences in mindsets and worldviews and provide a few travel tips for those people who would like to go on the bridge from mathematical to digital, or vice versa. (related to a manuscript under preparation with  Matan Gavish, Hebrew University)<br/>
_Keyrwords:_ machine learning, signal processing.

**Miki Elad**, Technion<br/>
_Title:_ The New Era of Image Denoising<br/>
_Abstract:_ Image denoising is one of the oldest and most studied problems in image processing. An extensive work over several decades has led to thousands of papers on this subject, and to many well-performing algorithms for this task. As expected, the era of deep learning has brought yet another revolution to this subfield, and took the lead in today’s ability for noise suppression in images. This talk focuses on recently discovered abilities and opportunities of image denoisers. We expose the possibility of using image denoisers for serving other problems, such as regularizing general inverse problems and serving as the engine for image synthesis. We also unveil the (strange?) idea that denoising and other inverse problems might not have a unique solution, as common algorithms would have you believe. Instead, we describe constructive ways to produce randomized and diverse high perceptual quality results for inverse problems.<br/>
_Keyrwords:_ signal processing, image processing, machine learning, denoising.

**Remi Gribonval**<br/>
_Title:_ TBA.<br/>
_Abstract:_ TBA.<br/>
_Keyrwords:_

**Stéphane Jaffard**, Université Paris-Est<br/>
_Title:_ Random Fourier series   vs.  random  wavelet series<br/>
_Abstract:_ The huge success of wavelet bases was the consequence of two key properties:  On one hand, the general framework of multiresolution analysis, built  by Stéphane Mallat, which led to the fast decomposition/reconstruction algorithms and to the  construction of compactly supported wavelets by Ingrid Daubechies;  and, on other hand,  the characterization of large classes of function spaces by simple conditions on wavelet coefficients, worked out by Yves Meyer (often referred to as the ``multiplier property'') and  which had direct and practical consequences in  statistics and in signal and image processing. These characterizations imply that the norm of a function is not greatly modified if its  wavelet coefficients suffer  perturbations,  which guarantees the numerical robustness of the reconstruction of a function from it wavelet coefficients,  in sharp contradistinction with Fourier series. We will expose  surprizing consequences of this property, which implies  that  the regularity properties of random wavelet series strongly differ from   those of random Fourier series.<br/>
_Keyrwords:_ Fourier transform, wavelet transform, multiresolution analysis.

**Jerome Kalifa**<br/>
_Title:_ A data science startup - Let It Wave’s meandering adventure, and its duller sisters.<br/>
_Abstract:_ In 2001, Stéphane Mallat founded Let It Wave with three of its students. The startup went through a fast-paced series of transformations, turning from its initial consulting activities to an ambitious fabless in consumer electronics for HDTV. A semi-success, the company is a good case study of a startup that originated from academic research.
This talk is the story of Let It Wave from its origins, Le Pennec’s thesis on bandlets, to its acquisition in 2008. As this adventure turned me into a serial entrepreneur rather than an academic, I will also briefly present the duller and wiser Lixoft, another company originating from research in statistics for clinical studies, and more recent projects stemming from data science.<br/>
_Keyrwords:_ startup, signal processing, video upscaling.

**Hamid Krim**, NCSU, Raleigh NC<br/>
_Title:_ Learning with Volterra Series (VNNs)<br/>
_Abstract:_ Machine Learning (ML) has reached an unprecedented performance in various inference problems arising in practice. The sample complexity and that of the model have, however, increasingly emerged as a serious limitation. Given the importance of a number of problems where these issues are central, we have revisited the Conv-net fundamental principle and have reformulated it from a Volterra Series perspective using a polynomial functional paradigm*. We propose a computational Convolutional Network solution which requires no activation function and provides a very competitive inference performance (often better) at a fraction of the sample and model complexity of the most competitive CNN architecture. * Homogeneous Polynomial Functional were first developed and formalized by Frechet.<br/>
_Keyrwords:_ machine learning,  Volterra Series, sampling complexity, polynomials.

**Gitta Kutyniok**,  LMU Munich<br/>
_Title:_ Reliable AI: From Applied Harmonic Analysis to Quantum Computing<br/>
_Abstract:_ The new wave of artificial intelligence is impacting industry, public life, and the sciences in an unprecedented manner. In mathematics, it has by now already led to paradigm changes in several areas. However, one current major drawback is the lack of reliability of such methodologies. In this talk, we will focus on the key aspects of reliability of deep neural networks, namely generalization and explainbility, and discuss a complete generalization result in the setting of graph neural networks and a novel explainbility approach based on applied harmonic analysis. Finally, we will briefly touch upon limitations as well, show that from a computability viewpoint digital hardware causes a serious problem for reliability, and reveal a surprising connection to novel computing approaches such as quantum computing.<br/>
_Keyrwords:_ harmonic analysis, machine learning, quantum computing.

**Yann Le Cun**<br/>
_Title:_ TBA.<br/>
_Abstract:_ TBA.<br/>
_Keyrwords:_

**Eric Moulines, Ecole Polytechnique**<br/>
_Title:_ Sampling through Exploration Exploitation.<br/>
_Abstract:_ We develop an explore-exploit Markov chain Monte Carlo algorithm (Ex2MCMC) that combines multiple global proposals and mobile moves. The proposed method is massively parallelizable and extremely computationally efficient. We prove the V-uniform geometric ergodicity of Ex2MCMC under realistic conditions and compute explicit bounds on the mixing rate showing the improvement due to multiple global moves. We show that Ex2MCMC allows fine-tuning of exploitation (local moves) and exploration (global moves) via a novel approach to propose dependent global moves. Finally, we develop an adaptive scheme, FlEx2MCMC, that learns the distribution of global trains through normalizing flows.
We illustrate the efficiency of Ex2MCMC and its adaptive versions in many classical sampling benchmarks. We also show that these algorithms improve the quality of sampling GANs as energy-based models.<br/>
_Keyrwords:_ machine learning, sampling, Markov chain Monte Carlo.

**Edouard Oyallon**<br/>
_Title:_ TBA.<br/>
_Abstract:_ TBA.<br/>
_Keyrwords:_

**Naoki Saito**, UC Davis<br/>
_Title:_ Multiscale basis dictionaries and scattering networks on simplicial complexes<br/>
_Abstract:_ I will discuss multiscale basis dictionaries, in particular, the Hierarchical Graph Laplacian Eigen Transform (HGLET) and the Generalized Haar-Walsh Transform (GHWT), which my group originally developed for analyzing signals measured on nodes of an input graph, but which we have recently generalized for signals defined on edges, triangles, tetrahedra, etc. of a given simplicial complex using the Hodge Laplacians. These dictionaries consist of redundant sets of multiscale basis vectors and the corresponding expansion coefficients of a given signal. These provide a large number of orthonormal bases among which one can select the most suitable basis for one's task using the best-basis algorithm and its relatives.
I will also discuss how to construct scattering networks for signals on simplicial complexes using the HGLET and the GHWT. Our new scattering networks cascade the moments (up to fourth order) of the modulus of the dictionary coefficients followed by the local averaging process. Consequently, the resulting features are robust to perturbations of input signals and invariant w.r.t. node permutations. I will demonstrate the usefulness of these dictionaries using the coauthorship/citation complex and the Science News article classification. This is joint work with Stefan Schonsheck and Eugene Shvarts.<br/>
_Keyrwords:_ machine learning, scattering transform, graphs.

**Guillermo Sapiro**, Duke<br/>
_Title:_ A Large-Scale Observational Study of the Causa Effects of a Behavioral Health Nudge<br/>
_Abstract:_ Nudges are interventions promoting healthy behavior without forbidding
options or significant incentives; the Apple Watch, for example,
encourages users to stand by delivering a notification if they have
been sitting for the first 50 minutes of an hour. Based on 76 billion
minutes of observational standing data from 160,000 subjects
in the public Apple Heart and Movement Study, we estimate the
causal effect of this notification using a novel regression discontinuity
design for time-series data with time-varying treatment. We show
that the nudge increases the probability of standing by up to 43.9%,
and remains effective with time. The nudge’s effectiveness increases
with age and it is independent of gender. Closing Apple Watch Activity
Rings, a visualization of participants’ daily progress in Move,
Exercise, and Stand, further increases the nudge’s impact. This work
demonstrates the effectiveness of behavioral health interventions and
introduces tools for investigating their causal effect from observations.
Joint work with Achille Nazaret.<br/>
_Keyrwords:_ causality, medicine, signal processing, machine learning.

**Shihab Shamma**<br/>
_Title:_ TBA.<br/>
_Abstract:_ TBA.<br/>
_Keyrwords:_

**Eero Simoncelli**<br/>
_Title:_ TBA.<br/>
_Abstract:_ TBA.<br/>
_Keyrwords:_

**Jean-Jacques Slotine**, MIT<br/>
_Title:_ Stable adaptation and learning<br/>
_Abstract:_ The human brain still largely outperforms robotic algorithms in most tasks, using computational elements 7 orders of magnitude slower than their artificial counterparts. Similarly, current large scale machine learning algorithms require millions of examples and close proximity to power plants, compared to the brain's few examples and 20W consumption. We study how modern nonlinear systems tools, such as contraction analysis, virtual dynamical systems, and adaptive nonlinear control can yield quantifiable insights about collective computation and learning in large dynamical networks. For instance, we show how stable implicit sparse regularization can be exploited in adaptive prediction or control  to select relevant dynamic models out of plausible physically-based candidates, and how most elementary results on gradient descent based on convexity  can be replaced by much more general results based on Riemannian contraction.<br/>
_Keyrwords:_ neuroscience, machine learning, neural networks, sparsity.

**Michael Unser**<br/>
_Title:_ TBA.<br/>
_Abstract:_ TBA.<br/>
_Keyrwords:_

**Martin Vetterli**, EPFL<br/>
_Title:_ Lippmann Photography: The Art and Science of Multispectral Imagery<br/>
_Abstract:_ Gabriel Lippmann won the 1908 Nobel Prize in Physics for colour photography. 
It is actually the first example of multispectral imaging. We provide a complete analysis of the process and show, both theoretically and experimentally, what spectrum is reflected from a Lippmann plate.  An algorithmic recovery of the original spectrum is proposed, as well as a digital version of Lippmann photography. We discuss the application to high density permanent three-dimensional storage, and finish with an example of science communication for the general public. Joint work with Gilles Baechler, Arnaud Latty, Michalina Pacholska,  Paolo Prandoni and Adam Scholefield. References: 1. Gilles Baechler, Arnaud Latty, Michalina Pacholska, Martin Vetterli, and Adam Scholefield,  “Shedding light on 19th century spectra by analyzing Lippmann photography,”  PNAS, April 27, 2021, Vol. 118, No. 17. ; 2.  Gilles Baechler, Arnaud Latty, Michalina Pacholska, Martin Vetterli, and Adam Scholefield,  “Lippmann Photography: A Signal Processing Perspective,”  IEEE Tr. on SP, July 2022.<br/>
_Keyrwords:_ computational imaging, multispectral imaging, science communication.

**Irene Waldspurger**<br/>
_Title:_ TBA.<br/>
_Abstract:_ TBA.<br/>
_Keyrwords:_

**Bin Yu**<br/>
_Title:_ TBA.<br/>
_Abstract:_ TBA.<br/>
_Keyrwords:_<br/>
_Keyrwords:_